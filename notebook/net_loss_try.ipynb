{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import utils\n",
    "from snntorch import surrogate\n",
    "import torch.nn.functional as F\n",
    "from snntorch import functional as SF\n",
    "import brevitas.nn as qnn \n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from networks_debug import *\n",
    "from dataloader import WisdmDatasetParser, WisdmDataset\n",
    "from torch.utils.data import  DataLoader\n",
    "from assistant import Assistant\n",
    "from stats import LearningStats\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "device = 'cuda'\n",
    "print(f'Using device {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "slope = 10\n",
    "# network parameters\n",
    "num_inputs = 6 \n",
    "num_steps = 40\n",
    "net_hidden_1 = 180\n",
    "net_hidden_2 = 400\n",
    "net_hidden_3 = 128\n",
    "num_outputs = 7\n",
    "pop_outputs = num_outputs * 10\n",
    "num_epochs = 200\n",
    "vth_in = 1.0\n",
    "vth_out = 1.0\n",
    "vth_recurrent = 1.0\n",
    "vth_enc_value =  1.0\n",
    "vth_std =  65 \n",
    "beta_in = 0.5\n",
    "beta_recurrent = 0.5\n",
    "beta_back = 0.6\n",
    "beta_out = 0.5\n",
    "encoder_dim = 25\n",
    "beta_std = 55\n",
    "lr = 0.002\n",
    "drop_recurrent =0.15\n",
    "drop_back = 0.15\n",
    "drop_out = 0.15\n",
    "# spiking neuron parameters\n",
    "beta = 0.8  # neuron decay rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'data_watch_subset_0_40.npz'\n",
    "DATASET_SUBSET = 'subset_2'\n",
    "PATIENCE = 12\n",
    "TRAIN_FOLDER_NAME = 'Trained'\n",
    "NUM_WORKERS = 8\n",
    "NET_OUTPUT_DIM = 7\n",
    "NET_INPUT_DIM = 6\n",
    "NUM_EPOCHS = 200\n",
    "SEARCH_SPACE_SHUFFLE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franzhd/miniconda3/envs/snn_torch/lib/python3.10/site-packages/brevitas/nn/mixin/base.py:77: UserWarning: Keyword arguments are being passed but they not being used.\n",
      "  warn('Keyword arguments are being passed but they not being used.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n",
      "(6,)\n",
      "ytrain shape (55404, 18)\n",
      "yval shape (18468, 18)\n",
      "ytest shape (18469, 18)\n",
      "num classes train dataset: 7 occurrences of each class:[3102 2981 3047 3150 3087 3058 3154]\n",
      "num classes eval dataset: 7 occurrences of each class:[1122  982  996 1110 1053 1039 1066]\n",
      "num classes test dataset: 7 occurrences of each class:[1046  989 1036 1076 1026 1067 1014]\n",
      "(21579, 6, 40)\n",
      "Using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]/home/franzhd/.local/lib/python3.10/site-packages/torch/_tensor.py:1394: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1908.)\n",
      "  return super().rename(names)\n",
      "[Epoch  0/200] Training: loss =     1.96891                          accuracy = 0.16406 :   2%|â–         | 1/43 [00:01<00:51,  1.22s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm_dataloader): \u001b[38;5;66;03m# training loop\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28minput\u001b[39m, label \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 56\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43massistant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     tqdm_dataloader\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m2d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_EPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstats\u001b[38;5;241m.\u001b[39mtraining\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m tqdm_dataloader \u001b[38;5;241m=\u001b[39m tqdm(val_loader)\n",
      "File \u001b[0;32m~/snntorch_network/notebook/../src/assistant.py:118\u001b[0m, in \u001b[0;36mAssistant.train\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    116\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         output, net_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(output, target)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlam \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# add net_loss before backward step\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/snntorch_network/notebook/../src/networks_debug.py:173\u001b[0m, in \u001b[0;36mQuantAhpcNetwork.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    170\u001b[0m         layer1_acc\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39mclone())   \n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaky1(x)\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/snn_torch/lib/python3.10/site-packages/brevitas/nn/quant_linear.py:66\u001b[0m, in \u001b[0;36mQuantLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Union[Tensor, QuantTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, QuantTensor]:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/snn_torch/lib/python3.10/site-packages/brevitas/nn/quant_layer.py:302\u001b[0m, in \u001b[0;36mQuantWeightBiasInputOutputLayer.forward_impl\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    299\u001b[0m output_zero_point \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    300\u001b[0m output_signed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# shortcut execution through the export impl during export\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/snn_torch/lib/python3.10/site-packages/brevitas/nn/mixin/base.py:161\u001b[0m, in \u001b[0;36mQuantLayerMixin.unpack_input\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_global_is_quant_layer(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Hack to recognize a QuantTensor that has decayed to a tuple\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# when used as input to tracing (e.g. during ONNX export)\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tracing_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inp, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28mlen\u001b[39m(inp) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(QuantTensor\u001b[38;5;241m.\u001b[39m_fields) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m([\u001b[38;5;28misinstance\u001b[39m(t, Tensor) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inp])):\n\u001b[1;32m    163\u001b[0m     inp \u001b[38;5;241m=\u001b[39m QuantTensor(\u001b[38;5;241m*\u001b[39minp)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inp, QuantTensor):\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# don't cache values during export pass\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_folder = TRAIN_FOLDER_NAME\n",
    "os.makedirs(trained_folder, exist_ok=True)\n",
    "dataset = WisdmDatasetParser(f'{Path.home()}/snntorch_network/data/{DATASET_NAME}', norm=None, class_sublset=DATASET_SUBSET)\n",
    "train_set = dataset.get_training_set()\n",
    "val_set = dataset.get_validation_set()\n",
    "\n",
    "\n",
    "data, label = train_set\n",
    "print(data.shape)\n",
    "\n",
    "train_dataset = WisdmDataset(train_set)\n",
    "val_dataset = WisdmDataset(val_set)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=int(batch_size), shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader  = DataLoader(dataset= val_dataset, batch_size=int(batch_size), shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using device {device}')\n",
    "\n",
    "grad = surrogate.fast_sigmoid(slope) #use slope for HPO\n",
    "\n",
    "net_loss = regularization_loss(0.1, 0.03, 40)\n",
    "\n",
    "net = QuantAhpcNetwork(NET_INPUT_DIM, int(net_hidden_1), int(net_hidden_2), NET_OUTPUT_DIM, grad,\n",
    "                    vth_in=vth_in, vth_recurrent=vth_recurrent, vth_out=vth_out,\n",
    "                    beta_in=beta_in, beta_recurrent=beta_recurrent, beta_back=beta_back, beta_out=beta_out,\n",
    "                    # encoder_dim=int(encoder_dim),\n",
    "                    # vth_enc_value=vth_enc_value, vth_std=vth_std, beta_std=beta_std,\n",
    "                    drop_recurrent=drop_recurrent, drop_back=drop_back, drop_out=drop_out,\n",
    "                    time_dim=2, layer_loss=net_loss).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "    T_max=4690, \n",
    "    eta_min=0, \n",
    "    last_epoch=-1\n",
    ")\n",
    "\n",
    "loss_fn = SF.loss.ce_count_loss()\n",
    "\n",
    "stats = LearningStats()\n",
    "assistant = Assistant(net, loss_fn, optimizer, stats, classifier=True, scheduler=scheduler, lam=1.0)\n",
    "\n",
    "count = 0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    labels = []\n",
    "    outputs = []\n",
    "    # if epoch % 20 == 0:\n",
    "    #     assistant.reduce_lr()\n",
    "    if count < PATIENCE:\n",
    "        count = count+1\n",
    "        tqdm_dataloader = tqdm(train_loader)\n",
    "        for _, batch in enumerate(tqdm_dataloader): # training loop\n",
    "            input, label = batch\n",
    "            \n",
    "            output = assistant.train(input, label)\n",
    "            tqdm_dataloader.set_description(f'\\r[Epoch {epoch:2d}/{NUM_EPOCHS}] Training: {stats.training}')\n",
    "\n",
    "        tqdm_dataloader = tqdm(val_loader)\n",
    "        for _, batch in enumerate(tqdm_dataloader): #eval loop\n",
    "            input, label = batch\n",
    "            output = assistant.test(input, label)\n",
    "            tqdm_dataloader.set_description(f'\\r[Epoch {epoch:2d}/{NUM_EPOCHS}] Validation: {stats.testing}')\n",
    "        \n",
    "            if len(outputs) == 0:\n",
    "                outputs = output.to('cpu').detach()\n",
    "                labels = label.to('cpu').detach()\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, output.to('cpu').detach()), dim=1)\n",
    "                labels = torch.cat((labels, label.to('cpu').detach()))\n",
    "\n",
    "        stats.update()\n",
    "\n",
    "        if stats.testing.best_accuracy:\n",
    "            count = 0\n",
    "            _, predictions = outputs.sum(dim=0).max(1)\n",
    "            gen_confusion_matrix(predictions,labels, f'./{trained_folder}/')\n",
    "            net.save_to_npz(f'./{trained_folder}/network_best.npz')\n",
    "            stats.save( f'./{trained_folder}/')\n",
    "        del labels\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "\n",
    "net.from_npz(f'./{trained_folder}/network_best.npz')\n",
    "\n",
    "tqdm_dataloader = tqdm(val_loader)\n",
    "for _, batch in enumerate(tqdm_dataloader): #eval loop\n",
    "    input, label = batch\n",
    "    output = assistant.test(input, label)\n",
    "    tqdm_dataloader.set_description(f'\\r[Epoch {epoch:2d}/{NUM_EPOCHS}] Final Validation: {stats.testing}')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'networks_debug.QuantAhpcNetwork'>\n"
     ]
    }
   ],
   "source": [
    "print(type(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monitor.monitored_layers=['leaky1', 'recurrent', 'recurrent.recurrent.activation', 'leaky2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# net.from_npz(f'./{trained_folder}/network_best.npz')\n",
    "net.from_npz(f'./Trained_subset_2_NO_ENCODER/network_best.npz')\n",
    "net.to(device)\n",
    "\n",
    "from snntorch.functional import probe\n",
    "\n",
    "monitor = probe.OutputMonitor(net, instance = snn.Leaky)\n",
    "monitor.enable()\n",
    "\n",
    "tqdm_dataloader = tqdm(val_loader)\n",
    "for _, batch in enumerate(tqdm_dataloader): #eval loop\n",
    "    input, label = batch\n",
    "    net.debug_init()\n",
    "    output = assistant.test(input, label)\n",
    "\n",
    "    spike, state = net.get_monitor_results()\n",
    "    #for i in range(0, 10):\n",
    "    # plt.plot(spike[:,0,:].cpu().numpy())\n",
    "    # plt.show()\n",
    "    # print(f'monitor.records={spike.records}')\n",
    "    # print(f'monitor[0]={spike[0]}')\n",
    "    print(f'monitor.monitored_layers={spike.monitored_layers}')\n",
    "    break\n",
    "        \n",
    "    tqdm_dataloader.set_description(f'\\r[Epoch {epoch:2d}/{NUM_EPOCHS}] Final Validation: {stats.testing}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_monitor=['leaky1', 'recurrent.recurrent.activation', 'leaky2']\n"
     ]
    }
   ],
   "source": [
    "print(f'state_monitor={state.monitored_layers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_monitor[0]=40\n",
      "state_monitor[0]=torch.Size([512, 180])\n"
     ]
    }
   ],
   "source": [
    "print(f\"state_monitor[0]={len(state['leaky1'])}\")\n",
    "print(f\"state_monitor[0]={state['leaky1'][0].shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
