{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import utils\n",
    "from snntorch import surrogate\n",
    "import torch.nn.functional as F\n",
    "from snntorch import functional as SF\n",
    "import brevitas.nn as qnn \n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from networks_debug import *\n",
    "from dataloader import WisdmDatasetParser, WisdmDataset\n",
    "from torch.utils.data import  DataLoader\n",
    "from assistant import Assistant\n",
    "from stats import LearningStats\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "device = 'cuda'\n",
    "print(f'Using device {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "slope = 10\n",
    "# network parameters\n",
    "num_inputs = 6 \n",
    "num_steps = 40\n",
    "net_hidden_1 = 180\n",
    "net_hidden_2 = 400\n",
    "net_hidden_3 = 128\n",
    "num_outputs = 7\n",
    "pop_outputs = num_outputs * 10\n",
    "num_epochs = 200\n",
    "vth_in = 0.4\n",
    "vth_out = 0.5\n",
    "vth_recurrent = 1.0\n",
    "vth_enc_value =  0.4\n",
    "vth_std =  65 \n",
    "beta_in = 0.5\n",
    "beta_recurrent = 0.5\n",
    "beta_back = 0.7\n",
    "beta_out = 0.2\n",
    "encoder_dim = 25\n",
    "beta_std = 55\n",
    "lr = 0.002\n",
    "drop_recurrent =0.15\n",
    "drop_back = 0.35\n",
    "drop_out = 0.35\n",
    "# spiking neuron parameters\n",
    "beta = 0.8  # neuron decay rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'data_watch_subset_0_40.npz'\n",
    "DATASET_SUBSET = '7BC'\n",
    "PATIENCE = 12\n",
    "TRAIN_FOLDER_NAME = 'Trained'\n",
    "NUM_WORKERS = 8\n",
    "NET_OUTPUT_DIM = 7\n",
    "NET_INPUT_DIM = 6\n",
    "NUM_EPOCHS = 200\n",
    "SEARCH_SPACE_SHUFFLE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franzhd/miniconda3/envs/snn_torch/lib/python3.10/site-packages/brevitas/nn/mixin/base.py:77: UserWarning: Keyword arguments are being passed but they not being used.\n",
      "  warn('Keyword arguments are being passed but they not being used.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n",
      "(6,)\n",
      "ytrain shape (55404, 18)\n",
      "yval shape (18468, 18)\n",
      "ytest shape (18469, 18)\n",
      "num classes train dataset: 7 occurrences of each class:[3066 3102 2981 3047 3095 2973 3213]\n",
      "num classes eval dataset: 7 occurrences of each class:[ 968 1122  982  996  966 1007 1077]\n",
      "num classes test dataset: 7 occurrences of each class:[1061 1046  989 1036  965  982 1054]\n",
      "(21477, 6, 40)\n",
      "Using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:00<?, ?it/s]/home/franzhd/.local/lib/python3.10/site-packages/torch/_tensor.py:1394: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1908.)\n",
      "  return super().rename(names)\n",
      "[Epoch  0/200] Training: loss =     1.88518                          accuracy = 0.26582 : 100%|██████████| 42/42 [00:26<00:00,  1.59it/s]\n",
      "[Epoch  0/200] Validation: loss =     1.63769                          accuracy = 0.33577 : 100%|██████████| 14/14 [00:04<00:00,  3.23it/s]\n",
      "[Epoch  1/200] Training: loss =     1.59454 (min =     1.88518)     accuracy = 0.41761 (max = 0.26582) : 100%|██████████| 42/42 [00:26<00:00,  1.60it/s]\n",
      "[Epoch  1/200] Validation: loss =     1.52804 (min =     1.63769)     accuracy = 0.38915 (max = 0.33577) : 100%|██████████| 14/14 [00:04<00:00,  2.90it/s]\n",
      "[Epoch  2/200] Training: loss =     1.51676 (min =     1.59454)     accuracy = 0.45411 (max = 0.41761) : 100%|██████████| 42/42 [00:26<00:00,  1.56it/s]\n",
      "[Epoch  2/200] Validation: loss =     1.50170 (min =     1.52804)     accuracy = 0.44001 (max = 0.38915) : 100%|██████████| 14/14 [00:04<00:00,  3.11it/s]\n",
      "[Epoch  3/200] Training: loss =     1.44848 (min =     1.51676)     accuracy = 0.48764 (max = 0.45411) : 100%|██████████| 42/42 [00:26<00:00,  1.59it/s]\n",
      "[Epoch  3/200] Validation: loss =     1.40309 (min =     1.50170)     accuracy = 0.48736 (max = 0.44001) : 100%|██████████| 14/14 [00:04<00:00,  3.10it/s]\n",
      "[Epoch  4/200] Training: loss =     1.35346 (min =     1.44848)     accuracy = 0.52596 (max = 0.48764) : 100%|██████████| 42/42 [00:26<00:00,  1.62it/s]\n",
      "[Epoch  4/200] Validation: loss =     1.30612 (min =     1.40309)     accuracy = 0.52655 (max = 0.48736) : 100%|██████████| 14/14 [00:04<00:00,  3.17it/s]\n",
      "[Epoch  5/200] Training: loss =     1.29068 (min =     1.35346)     accuracy = 0.54402 (max = 0.52596) : 100%|██████████| 42/42 [00:26<00:00,  1.61it/s]\n",
      "[Epoch  5/200] Validation: loss =     1.21095 (min =     1.30612)     accuracy = 0.57319 (max = 0.52655) : 100%|██████████| 14/14 [00:04<00:00,  3.16it/s]\n",
      "[Epoch  6/200] Training: loss =     1.23838 (min =     1.29068)     accuracy = 0.55254 (max = 0.54402) : 100%|██████████| 42/42 [00:26<00:00,  1.62it/s]\n",
      "[Epoch  6/200] Validation: loss =     1.10206 (min =     1.21095)     accuracy = 0.59033 (max = 0.57319) : 100%|██████████| 14/14 [00:04<00:00,  3.28it/s]\n",
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "trained_folder = TRAIN_FOLDER_NAME\n",
    "os.makedirs(trained_folder, exist_ok=True)\n",
    "dataset = WisdmDatasetParser(f'{Path.home()}/snntorch_network/data/{DATASET_NAME}', norm=None, class_sublset=DATASET_SUBSET)\n",
    "train_set = dataset.get_training_set()\n",
    "val_set = dataset.get_validation_set()\n",
    "\n",
    "\n",
    "data, label = train_set\n",
    "print(data.shape)\n",
    "\n",
    "train_dataset = WisdmDataset(train_set)\n",
    "val_dataset = WisdmDataset(val_set)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=int(batch_size), shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader  = DataLoader(dataset= val_dataset, batch_size=int(batch_size), shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using device {device}')\n",
    "\n",
    "grad = surrogate.fast_sigmoid(slope) #use slope for HPO\n",
    "\n",
    "net_loss = regularization_loss(0.1, 0.03, 40)\n",
    "\n",
    "net = QuantAhpcNetwork(NET_INPUT_DIM, int(net_hidden_1), int(net_hidden_2), NET_OUTPUT_DIM, grad,\n",
    "                    vth_in=vth_in, vth_recurrent=vth_recurrent, vth_out=vth_out,\n",
    "                    beta_in=beta_in, beta_recurrent=beta_recurrent, beta_back=beta_back, beta_out=beta_out,\n",
    "                    encoder_dim=int(encoder_dim),\n",
    "                    vth_enc_value=vth_enc_value, vth_std=vth_std, beta_std=beta_std,\n",
    "                    drop_recurrent=drop_recurrent, drop_back=drop_back, drop_out=drop_out,\n",
    "                    time_dim=2, layer_loss=net_loss).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "    T_max=4690, \n",
    "    eta_min=0, \n",
    "    last_epoch=-1\n",
    ")\n",
    "\n",
    "loss_fn = SF.loss.ce_count_loss()\n",
    "\n",
    "stats = LearningStats()\n",
    "assistant = Assistant(net, loss_fn, optimizer, stats, classifier=True, scheduler=scheduler, lam=1.0)\n",
    "\n",
    "count = 0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    labels = []\n",
    "    outputs = []\n",
    "    # if epoch % 20 == 0:\n",
    "    #     assistant.reduce_lr()\n",
    "    if count < PATIENCE:\n",
    "        count = count+1\n",
    "        tqdm_dataloader = tqdm(train_loader)\n",
    "        for _, batch in enumerate(tqdm_dataloader): # training loop\n",
    "            input, label = batch\n",
    "            \n",
    "            output = assistant.train(input, label)\n",
    "            tqdm_dataloader.set_description(f'\\r[Epoch {epoch:2d}/{NUM_EPOCHS}] Training: {stats.training}')\n",
    "\n",
    "        tqdm_dataloader = tqdm(val_loader)\n",
    "        for _, batch in enumerate(tqdm_dataloader): #eval loop\n",
    "            input, label = batch\n",
    "            output = assistant.test(input, label)\n",
    "            tqdm_dataloader.set_description(f'\\r[Epoch {epoch:2d}/{NUM_EPOCHS}] Validation: {stats.testing}')\n",
    "        \n",
    "            if len(outputs) == 0:\n",
    "                outputs = output.to('cpu').detach()\n",
    "                labels = label.to('cpu').detach()\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, output.to('cpu').detach()), dim=1)\n",
    "                labels = torch.cat((labels, label.to('cpu').detach()))\n",
    "\n",
    "        stats.update()\n",
    "\n",
    "        if stats.testing.best_accuracy:\n",
    "            count = 0\n",
    "            _, predictions = outputs.sum(dim=0).max(1)\n",
    "            gen_confusion_matrix(predictions,labels, f'./{trained_folder}/')\n",
    "            net.save_to_npz(f'./{trained_folder}/network_best.npz')\n",
    "            stats.save( f'./{trained_folder}/')\n",
    "\n",
    "        del outputs\n",
    "        del labels\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "\n",
    "net.load_from_npz(f'./{trained_folder}/network_best.npz')\n",
    "\n",
    "tqdm_dataloader = tqdm(val_loader)\n",
    "for _, batch in enumerate(tqdm_dataloader): #eval loop\n",
    "    input, label = batch\n",
    "    output = assistant.test(input, label)\n",
    "    tqdm_dataloader.set_description(f'\\r[Epoch {epoch:2d}/{NUM_EPOCHS}] Final Validation: {stats.testing}')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
